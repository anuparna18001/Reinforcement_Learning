{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For grid World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(state, action):\n",
    "    #From A to A'\n",
    "    if state == (0, 1): \n",
    "        next_state = (4,1)\n",
    "        r = 10\n",
    "        return next_state,r\n",
    "    #From B to B'\n",
    "    if state == (0, 3): \n",
    "        next_state = (2,3)\n",
    "        r = 5\n",
    "        return next_state,r\n",
    "    #Normal movements with 0 reward\n",
    "    next_state = (state[0] + action[0], state[1] + action[1])\n",
    "    if ((next_state[0] >= 0 and next_state[0] < 5) and\n",
    "        (next_state[1] >= 0 and next_state[1] < 5)):\n",
    "        r=0\n",
    "        return next_state, r\n",
    "    #If Wall\n",
    "    r = -1\n",
    "    return state, -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5 10.0 -0.2 5.0 -0.5]\n",
      " [-0.2 0.0 0.0 0.0 -0.2]\n",
      " [-0.2 0.0 0.0 0.0 -0.2]\n",
      " [-0.2 0.0 0.0 0.0 -0.2]\n",
      " [-0.5 -0.2 -0.2 -0.2 -0.5]] \n",
      "-------\n",
      "[[3.3 8.8 4.4 5.3 1.5]\n",
      " [1.5 3.0 2.3 1.9 0.5]\n",
      " [0.1 0.8 0.7 0.4 -0.4]\n",
      " [-1.0 -0.4 -0.3 -0.6 -1.2]\n",
      " [-1.8 -1.3 -1.2 -1.4 -1.9]] \n",
      "-------\n",
      "[[3.3 8.8 4.4 5.3 1.5]\n",
      " [1.5 3.0 2.3 1.9 0.6]\n",
      " [0.1 0.7 0.7 0.4 -0.4]\n",
      " [-1.0 -0.4 -0.4 -0.6 -1.2]\n",
      " [-1.9 -1.3 -1.2 -1.4 -2.0]] \n",
      "-------\n",
      "[[3.3 8.8 4.4 5.3 1.5]\n",
      " [1.5 3.0 2.3 1.9 0.5]\n",
      " [0.1 0.7 0.7 0.4 -0.4]\n",
      " [-1.0 -0.4 -0.4 -0.6 -1.2]\n",
      " [-1.9 -1.3 -1.2 -1.4 -2.0]] \n",
      "-------\n",
      "[[3.3 8.8 4.4 5.3 1.5]\n",
      " [1.5 3.0 2.3 1.9 0.5]\n",
      " [0.1 0.7 0.7 0.4 -0.4]\n",
      " [-1.0 -0.4 -0.4 -0.6 -1.2]\n",
      " [-1.9 -1.3 -1.2 -1.4 -2.0]] \n",
      "-------\n",
      "[[3.3 8.8 4.4 5.3 1.5]\n",
      " [1.5 3.0 2.3 1.9 0.5]\n",
      " [0.1 0.7 0.7 0.4 -0.4]\n",
      " [-1.0 -0.4 -0.4 -0.6 -1.2]\n",
      " [-1.9 -1.3 -1.2 -1.4 -2.0]] \n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "actions = [(0, -1), (0, 1), (1, 0), (-1, 0)]\n",
    "epochs = 90\n",
    "gamma = 0.9    #given in grid world example\n",
    "#since there are 4 actions possible, and each action is equi probable\n",
    "prob = 0.25\n",
    "v_pi = np.zeros((5, 5))\n",
    "while epochs>0:\n",
    "    v_n = np.zeros((5, 5))\n",
    "    #i and j represents all the states\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            #For each action\n",
    "            for a in actions:\n",
    "                state, reward = calculate((i, j), a)\n",
    "                v_n[i, j] = v_n[i, j] + prob * (reward + gamma * v_pi[state[0], state[1]])\n",
    "    v_pi = v_n\n",
    "    if epochs % 20 == 0: \n",
    "        print(v_pi, '\\n-------')\n",
    "    epochs = epochs - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.9 24.3 21.9 19.3 17.4]\n",
      " [19.7 21.9 19.7 17.7 16.0]\n",
      " [17.7 19.7 17.7 16.0 14.4]\n",
      " [15.9 17.7 16.0 14.4 12.9]\n",
      " [14.3 16.0 14.4 12.9 11.6]] \n",
      "-------\n",
      "[11.644192367880379, 9.457587818747719, 9.457587818747719, 11.644192367880379] \n",
      "-------\n",
      "[[22.0 24.4 22.0 19.4 17.5]\n",
      " [19.8 22.0 19.8 17.8 16.0]\n",
      " [17.8 19.8 17.8 16.0 14.4]\n",
      " [16.0 17.8 16.0 14.4 13.0]\n",
      " [14.4 16.0 14.4 13.0 11.7]] \n",
      "-------\n",
      "[11.67973581445638, 9.511761643737811, 9.511761643737811, 11.67973581445638] \n",
      "-------\n",
      "[[22.0 24.4 22.0 19.4 17.5]\n",
      " [19.8 22.0 19.8 17.8 16.0]\n",
      " [17.8 19.8 17.8 16.0 14.4]\n",
      " [16.0 17.8 16.0 14.4 13.0]\n",
      " [14.4 16.0 14.4 13.0 11.7]] \n",
      "-------\n",
      "[11.679736758540042, 9.511763082670386, 9.511763082670386, 11.679736758540042] \n",
      "-------\n",
      "[[22.0 24.4 22.0 19.4 17.5]\n",
      " [19.8 22.0 19.8 17.8 16.0]\n",
      " [17.8 19.8 17.8 16.0 14.4]\n",
      " [16.0 17.8 16.0 14.4 13.0]\n",
      " [14.4 16.0 14.4 13.0 11.7]] \n",
      "-------\n",
      "[11.679736758565118, 9.511763082708606, 9.511763082708606, 11.679736758565118] \n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "epochs = 90\n",
    "v_pi = np.zeros((5, 5))\n",
    "while epochs>0:\n",
    "    #For each state\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            v = []\n",
    "            #For each action\n",
    "            for a in actions:\n",
    "                state, reward = calculate((i, j), a)\n",
    "                v.append(reward + gamma * v_pi[state[0], state[1]])\n",
    "            #Select the optimal value\n",
    "            v_pi[i, j] = np.max(v)\n",
    "    if epochs % 20 == 0: \n",
    "        print(v_pi, '\\n-------')\n",
    "        print(v, '\\n-------')\n",
    "    epochs = epochs - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX : 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 -14.0 -20.0 -22.0]\n",
      " [-14.0 -18.0 -20.0 -20.0]\n",
      " [-20.0 -20.0 -18.0 -14.0]\n",
      " [-22.0 -20.0 -14.0 0.0]]\n"
     ]
    }
   ],
   "source": [
    "class grid_world():\n",
    "    def __init__(self,gamma=1,theta=0.01,policy=0.25):\n",
    "        self.gamma = gamma\n",
    "        self.theta = theta\n",
    "        self.policy = policy\n",
    "        self.actions = [(0, -1), (0, 1), (1, 0), (-1, 0)]\n",
    "        self.value = np.zeros((4, 4))\n",
    "        \n",
    "    def evaluate(self, state, action):\n",
    "        next_state = [state[0] + action[0], state[1] + action[1]]\n",
    "        if ((next_state[0] >= 0 and next_state[0] < 4) and (next_state[1] >= 0 and next_state[1] < 4)):\n",
    "            return next_state, -1\n",
    "        #Wall : cant take any action\n",
    "        return state, -1 \n",
    "    \n",
    "    def start_execution(self):\n",
    "        itr = 1\n",
    "        while True:\n",
    "            #Policy Evaluation\n",
    "            while True:\n",
    "                delta = 0 \n",
    "                for i in range(4):\n",
    "                    for j in range(4):\n",
    "                        if (i,j) == (0,0) or (i,j) == (3,3):\n",
    "                            continue\n",
    "                        v_prev = self.value[i, j]\n",
    "                        tmp = 0\n",
    "                        for a in self.actions:\n",
    "                            next_state, reward = self.evaluate([i,j], a)\n",
    "                            tmp = tmp + (self.policy * (reward + self.gamma * self.value[next_state[0], next_state[1]]))\n",
    "                        self.value[i, j] = tmp\n",
    "                        delta = max(delta, abs(self.value[i, j]-v_prev))\n",
    "                if delta < self.theta:\n",
    "                    break\n",
    "            #Policy Improvement\n",
    "            policy_stable = True\n",
    "            policy_changes = 0\n",
    "            for i in range(0,4):\n",
    "                for j in range(0,4):\n",
    "                    action_returns = []\n",
    "                    old_action = self.policy\n",
    "                    for a in self.actions:\n",
    "                        if (0 <= a[0] <= i) or (j >= abs(a[1]) > 0):\n",
    "                            s,r = self.evaluate([i, j], a)\n",
    "                            action_returns.append(r)\n",
    "                        else:\n",
    "                            action_returns.append(0)\n",
    "                    self.policy = self.actions[np.argmax(action_returns)]\n",
    "                    if old_action != self.policy:\n",
    "                        policy_stable = False\n",
    "                        policy_changes = policy_changes+1\n",
    "            #print('iteration ',itr)\n",
    "            #print('policies changed= ',policy_changes)\n",
    "            if policy_stable:\n",
    "                break\n",
    "            itr = itr + 1\n",
    "        #print('Updated Value')\n",
    "        print(self.value)\n",
    "        #print('Updated Policy')\n",
    "        #print(self.policy)\n",
    "        \n",
    "g = grid_world()\n",
    "g.start_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX : 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class car_rental():\n",
    "    def __init__(self, gamma=0.9, theta=1e-4):\n",
    "        self.gamma = gamma\n",
    "        self.theta = theta\n",
    "        self.action = np.arange(-5, 6)\n",
    "        self.policy = np.zeros((21, 21), dtype=int)\n",
    "        self.value = np.zeros((21, 21))\n",
    "        self.prob = []\n",
    "        for i in range(0,8):\n",
    "            for j in range(0,10):\n",
    "                for k in range(0,8):\n",
    "                    for l in range(0,6):\n",
    "                        self.prob.append(self.poisson(i, 3)*self.poisson(j, 4)*self.poisson(k, 3)*self.poisson(l, 2))\n",
    "        self.states = [(i, j) for i in range(21) for j in range(21)]\n",
    "    def poisson(self, n, l):\n",
    "        return np.exp(-l) * pow(l, n) / factorial(n)\n",
    "\n",
    "    def evaluate(self,state, r, v):\n",
    "        # shuttle one car\n",
    "        if r > 0: \n",
    "            returns = 2 \n",
    "        returns = (-2) * abs(r)\n",
    "        state = (min(state[0] - r, 20), min(state[1] + r, 20))\n",
    "        reward = []\n",
    "        for i in range(0,8):\n",
    "            for j in range(0,10):\n",
    "                for k in range(0,8):\n",
    "                    for l in range(0,6):\n",
    "                        if (min(state[0] - min(state[0], i) + k, 20) > 10 or min(state[1] - min(state[1], j) + l, 20) > 10):\n",
    "                            reward.append((min(state[0], i) + min(state[1], j))*10 + 4)\n",
    "                        else:\n",
    "                            #Penalty for more than 10 cars\n",
    "                            reward.append((min(state[0], i) + min(state[1], j))*10)\n",
    "        reward = np.array(reward)\n",
    "        new_state = []\n",
    "        for i in range(0,8):\n",
    "            for j in range(0,10):\n",
    "                for k in range(0,8):\n",
    "                    for l in range(0,6):\n",
    "                        new_state.append((min(state[0] - min(state[0], i) + k, 20), min(state[1] - min(state[1], j) + l, 20)))\n",
    "        new_state = np.array(new_state)\n",
    "        returns = returns + np.sum(self.prob * (reward + self.gamma * v[new_state[:,0], new_state[:,1]]))\n",
    "        return returns\n",
    "\n",
    "    def start_execution(self):\n",
    "        itr = 0\n",
    "        while 1:\n",
    "            #Policy evaluation\n",
    "            while 1:\n",
    "                delta = 0\n",
    "                for state in self.states:\n",
    "                    v_prev = self.value[state[0], state[1]]\n",
    "                    self.value[state[0], state[1]] = self.evaluate([state[0], state[1]], self.policy[state[0], state[1]], self.value)\n",
    "                    delta = max(delta, abs(self.value[state[0], state[1]]-v_prev))\n",
    "                if delta < self.theta:\n",
    "                    break\n",
    "            #Policy Improvement\n",
    "            policy_stable = True\n",
    "            policy_changes = 0\n",
    "            for state in self.states:\n",
    "                action_returns = []\n",
    "                old_action = self.policy[state[0], state[1]]\n",
    "                for a in self.action:\n",
    "                    if (0 <= a <= state[0]) or (state[1] >= abs(a) > 0):\n",
    "                        action_returns.append(self.evaluate([state[0], state[1]], a, self.value))\n",
    "                    else:\n",
    "                        action_returns.append(-np.Infinity)\n",
    "                self.policy[state[0], state[1]] = self.action[np.argmax(action_returns)]\n",
    "                if old_action != self.policy[state[0], state[1]]:\n",
    "                    policy_stable = False\n",
    "                    policy_changes = policy_changes+1\n",
    "            print('iteration ',itr)\n",
    "            print('policies changed= ',policy_changes)\n",
    "            if policy_stable:\n",
    "                break\n",
    "            itr = itr + 1\n",
    "        print('Updated Value')\n",
    "        print(self.value)\n",
    "        print('Updated Policy')\n",
    "        print(self.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "policies changed=  285\n",
      "iteration  1\n",
      "policies changed=  226\n",
      "iteration  2\n",
      "policies changed=  38\n",
      "iteration  3\n",
      "policies changed=  2\n",
      "iteration  4\n",
      "policies changed=  0\n",
      "Updated Value\n",
      "[[257.32008371 266.80760209 276.14474633 285.16100729 293.70485113\n",
      "  301.69899453 309.14420386 316.50958833 323.45815306 330.30972033\n",
      "  336.84061491 343.08072206 349.14973396 355.14606527 361.07852781\n",
      "  366.94593478 372.71761995 378.26365072 383.51111251 388.42851957\n",
      "  393.03582042]\n",
      " [266.69395948 276.18139568 285.51813814 294.53339024 303.07548248\n",
      "  311.06722322 318.50958984 325.45815456 332.30972181 338.84061638\n",
      "  345.08072352 351.1497354  357.14606671 363.07852924 368.94593595\n",
      "  374.71762111 380.26365189 385.51111367 390.42852074 395.03582121\n",
      "  399.54134222]\n",
      " [275.5969947  285.08405483 294.41896348 303.42962457 311.96378538\n",
      "  319.94474534 327.37455673 334.30972393 340.84061848 347.0807256\n",
      "  353.14973748 359.14606878 365.0785313  370.9459378  376.71762296\n",
      "  382.26365373 387.51111552 392.4285226  397.03582263 401.54134366\n",
      "  405.6872674 ]\n",
      " [283.74324152 293.22937147 302.5597506  311.55909755 320.07379489\n",
      "  328.0285125  335.42820078 342.33194233 348.83143315 355.04045093\n",
      "  361.07858398 367.04433878 372.94593983 378.71762499 384.26365577\n",
      "  389.51111757 394.42852466 399.03582445 403.54134551 407.68726928\n",
      "  411.42567341]\n",
      " [291.2293736  300.55975238 309.8614466  318.84060906 327.32069514\n",
      "  335.22903421 342.57608045 349.4258834  355.87273072 362.0308379\n",
      "  368.01918748 373.93591783 379.7879312  385.50805256 390.99889234\n",
      "  396.18579985 401.03582633 405.54134743 409.68727124 413.42567542\n",
      "  416.7399626 ]\n",
      " [298.55975427 307.86144812 316.84061052 325.38984956 333.81996859\n",
      "  341.66160143 348.93343971 355.70699824 362.08040703 368.16823441\n",
      "  374.08795061 379.9365228  385.71880951 391.36626464 396.78039994\n",
      "  401.88549834 406.64765763 411.05880419 415.1046014  418.73996464\n",
      "  421.88562117]\n",
      " [305.8614497  314.84061185 323.38985087 331.81996996 339.77631716\n",
      "  347.53533668 354.7141883  361.39364359 367.6763542  373.67667696\n",
      "  379.5092489  385.26885358 390.95799782 396.50778646 401.82038809\n",
      "  406.82069559 411.47498358 415.7752712  419.7081278  423.2312068\n",
      "  426.27036105]\n",
      " [312.84061301 321.38985208 329.81997111 337.77631846 345.53533802\n",
      "  353.06194021 360.13786633 366.71233465 372.89220816 378.79038087\n",
      "  384.5168893  390.16321024 395.72992919 401.15019033 406.3300485\n",
      "  411.19771547 415.72120583 419.89317439 423.70104496 427.10478272\n",
      "  430.03452851]\n",
      " [319.38985315 327.81997205 335.77631955 343.53533913 351.06194151\n",
      "  358.41364085 365.38461959 371.85008448 377.91978589 383.70321447\n",
      "  389.30360696 394.80793974 400.21614708 405.46726746 410.47596847\n",
      "  415.17741055 419.54311328 423.56663733 427.2357974  430.51208375\n",
      "  433.32882331]\n",
      " [325.81997272 333.77632046 341.53533999 349.06194259 356.41364212\n",
      "  363.72626479 370.5957094  376.95276846 382.9082411  388.56600489\n",
      "  394.02016289 399.35202116 404.56270498 409.60189524 414.39844936\n",
      "  418.89854627 423.07893396 426.9340002  430.45106978 433.59204651\n",
      "  436.29217479]\n",
      " [331.77632112 339.53534061 347.06194345 354.41364319 361.72626605\n",
      "  369.01403291 375.78555732 382.03455724 387.87146345 393.39296455\n",
      "  398.68233889 403.81441586 408.79328471 413.58340964 418.13256473\n",
      "  422.40127475 426.37277879 430.04202079 433.39493806 436.39285509\n",
      "  438.97193375]\n",
      " [337.53534098 345.06194406 352.41364405 359.72626712 367.01403417\n",
      "  374.21135074 380.88450793 387.02193477 392.7336389  398.10916598\n",
      "  403.22082223 408.13689612 412.8653468  417.38715482 421.67092138\n",
      "  425.69284368 429.44315386 432.91724967 436.09932214 438.94969906\n",
      "  441.40501011]\n",
      " [343.06194444 350.41364468 357.726268   365.01403527 372.21135202\n",
      "  379.20681335 385.77472798 391.79129003 397.36775602 402.58859941\n",
      "  407.51696675 412.21550188 416.69570432 420.95354912 424.97663003\n",
      "  428.75555136 432.28714489 435.56751186 438.5795552  441.28298565\n",
      "  443.61511582]\n",
      " [348.41364506 355.72626865 363.01403618 370.21135316 377.20681468\n",
      "  383.90755886 390.35719347 396.2381552  401.66590506 406.72339808\n",
      "  411.46790537 415.95810811 420.20781703 424.224076   428.00884384\n",
      "  431.56389424 434.891521   437.98894936 440.83877837 443.4010019\n",
      "  445.61425368]\n",
      " [353.72626905 361.01403685 368.21135412 375.20681587 381.90756025\n",
      "  388.357195   394.58827929 400.31583842 405.57921661 410.46382807\n",
      "  415.02483398 419.31900078 423.3610381  427.16450275 430.74028227\n",
      "  434.09741086 437.24210362 440.17295392 442.87318539 445.30396024\n",
      "  447.40587196]\n",
      " [359.01403727 366.21135483 373.20681689 379.90756151 386.35719641\n",
      "  392.58828092 398.46643862 404.02338568 409.10716128 413.80911029\n",
      "  418.18568031 422.29375033 426.14792662 429.76454882 433.15882843\n",
      "  436.34358961 439.32737286 442.10999576 444.67575943 446.98746567\n",
      "  448.98799035]\n",
      " [364.21135528 371.20681765 377.90756259 384.35719761 390.58828244\n",
      "  396.46644036 402.02338766 407.36943543 412.26235185 416.77414416\n",
      "  420.96513321 424.89407106 428.57508432 432.02495784 435.26012497\n",
      "  438.29467774 441.13808125 443.79088493 446.23838025 448.44497623\n",
      "  450.35575079]\n",
      " [369.20681812 375.9075634  382.3571985  388.58828372 394.46644198\n",
      "  400.0233895  405.36943753 410.34347876 415.04217854 419.36241478\n",
      "  423.37000524 427.12689783 430.64688392 433.94613425 437.04064401\n",
      "  439.94424529 442.66626838 445.20734674 447.55331233 449.66977584\n",
      "  451.50361837]\n",
      " [373.9075639  380.35719904 386.58828466 392.46644335 398.02339105\n",
      "  403.36943948 408.34348098 413.04218108 417.41898643 421.5562719\n",
      "  425.39023009 428.98673645 432.35964734 435.52433966 438.4957917\n",
      "  441.286881   443.90615376 446.35374123 448.61545202 450.65752865\n",
      "  452.42809337]\n",
      " [378.27354134 384.58828523 390.46644434 396.02339217 401.36944111\n",
      "  406.34348302 411.0421834  415.41898905 419.55627488 423.39023348\n",
      "  427.00549485 430.46129373 433.70660877 436.75627388 439.62431694\n",
      "  442.32255499 444.85850443 447.23143259 449.42666884 451.41055913\n",
      "  453.13190689]\n",
      " [382.30290252 388.46644493 394.02339284 399.36944231 404.34348493\n",
      "  409.04218555 413.41899232 417.55627853 421.39023757 425.00550129\n",
      "  428.46130082 431.70661658 434.75628248 437.65092177 440.43826405\n",
      "  443.06514081 445.53810729 447.8554914  450.0019297  451.94353158\n",
      "  453.62935461]]\n",
      "Updated Policy\n",
      "[[ 0  0  0  0  0  0  0 -1 -1 -2 -2 -2 -2 -2 -2 -3 -3 -3 -3 -3 -4]\n",
      " [ 0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -2 -2 -2 -2 -2 -3 -3]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 2  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  2  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  2  2  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  3  2  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  3  3  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  4  3  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  2  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  2  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  3  2  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  4  3  2  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  5  4  3  3  2  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  5  4  4  3  2  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  5  5  4  3  3  2  2  2  1  1  1  1  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "c = car_rental()\n",
    "c.start_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
